> #csc570 DS midtermprep
> 
> #print(getwd())
> setwd("//ad.uillinois.edu/engr/USERS/mdmurph/WORKING FILES/OL_ED/UIS MCS/2016 Fall/csc570 data science essentials/new midterm")
> 
> #1 load the dataset
> train <- read.csv("midterm_train.csv", stringsAsFactors = + FALSE)
> 
> #2 overall structure of the dataset using str()
> str(train)
'data.frame':	160000 obs. of  51 variables:
 $ x0 : num  -0.167 -0.15 -0.322 -0.246 -0.273 ...
 $ x1 : num  -3.962 -0.586 -1.43 5.077 0.306 ...
 $ x2 : num  4.62 27.84 12.25 -24.15 -11.35 ...
 $ x3 : num  2.48 4.15 6.59 3.64 1.68 ...
 $ x4 : num  -1.8 6.43 -5.3 6.51 2.93 ...
 $ x5 : num  0.805 -2.427 -11.311 2.29 -0.617 ...
 $ x6 : num  6.72 40.48 17.81 -35.11 -16.51 ...
 $ x7 : num  -14.79 -6.73 11.06 -18.91 27.53 ...
 $ x8 : num  -1.041 0.896 5.326 -0.337 1.2 ...
 $ x9 : num  -4.2 0.33 -2.63 -5.57 -4.31 ...
 $ x10: num  6.19 -11.71 1.57 -2 6.67 ...
 $ x11: num  13.25 -2.35 -4.17 -19.29 1.97 ...
 $ x12: num  25.7 -25 12.1 11 -28.1 ...
 $ x13: num  -5.02 9.8 -5.16 -5.91 -1.26 ...
 $ x14: num  10.5 -10.96 7.3 2.51 5.76 ...
 $ x15: num  -2.518 1.504 -2.192 1.292 0.473 ...
 $ x16: num  2.12 -2.4 -4.07 -2.5 -1.15 ...
 $ x17: num  5.87 -9.3 -7.68 -15.72 -14.12 ...
 $ x18: num  -6.67 -2 4.04 -2.74 4.53 ...
 $ x19: num  1.79 5.05 -6.63 1.12 -1.28 ...
 $ x20: num  -1.91 -5.81 1.7 1.92 -9.03 ...
 $ x21: num  -1.74 10.81 -2.42 -14.18 -7.04 ...
 $ x22: num  -2.517 -0.478 2.468 1.471 -1.979 ...
 $ x23: num  3.55 10.59 -5.27 -11.48 -16 ...
 $ x24: chr  "euorpe" "asia" "asia" "asia" ...
 $ x25: num  -0.8013 0.8188 -0.7183 -0.0524 -0.2234 ...
 $ x26: num  1.143 -0.643 -0.567 -0.559 0.351 ...
 $ x27: num  1.005 0.751 4.171 9.216 1.811 ...
 $ x28: num  -18.47 3.75 11.52 30.6 -4.09 ...
 $ x29: chr  "July" "Aug" "July" "July" ...
 $ x30: chr  "tuesday" "wednesday" "wednesday" "wednesday" ...
 $ x31: num  -3.852 1.392 -3.262 -2.285 0.921 ...
 $ x32: chr  "0.0%" "-0.02%" "-0.01%" "0.01%" ...
 $ x33: num  -1.94 2.211 0.42 -3.443 -0.432 ...
 $ x34: num  -5.49 -4.46 -3.8 4.42 12.17 ...
 $ x35: num  0.627 1.035 -0.763 1.165 -0.168 ...
 $ x36: num  -0.874 0.228 -1.613 3.033 -0.342 ...
 $ x37: chr  "$1313.96" "$1962.78" "$430.47" "$-2366.29" ...
 $ x38: num  -1.354 32.817 -0.333 14.189 -12.579 ...
 $ x39: num  -5.19 -5.15 8.73 -6.39 1.13 ...
 $ x40: num  -10.612 2.147 -0.863 12.084 30.005 ...
 $ x41: num  -1.497 36.293 -0.368 15.692 -13.911 ...
 $ x42: num  5.41 4.49 9.09 -7.47 -5.23 ...
 $ x43: num  -2.326 0.763 -0.69 2.941 1.784 ...
 $ x44: num  1.67 6.53 -2.73 -6.42 3.96 ...
 $ x45: num  -0.264 1.008 0.754 0.42 -0.097 ...
 $ x46: num  60.8 15.8 30.9 -72.4 -14.1 ...
 $ x47: num  -7.69 -4.897 -7.429 5.361 -0.208 ...
 $ x48: num  0.152 -0.32 -2.091 1.806 -0.895 ...
 $ x49: num  -8.04 16.72 -7.87 -7.67 15.72 ...
 $ y  : int  0 0 0 0 1 0 1 1 0 1 ...
> 
> #4 delete the rows with missing values in horsepower
> train<-na.omit(train)
> str(train)
'data.frame':	158534 obs. of  51 variables:
 $ x0 : num  -0.167 -0.15 -0.322 -0.246 -0.273 ...
 $ x1 : num  -3.962 -0.586 -1.43 5.077 0.306 ...
 $ x2 : num  4.62 27.84 12.25 -24.15 -11.35 ...
 $ x3 : num  2.48 4.15 6.59 3.64 1.68 ...
 $ x4 : num  -1.8 6.43 -5.3 6.51 2.93 ...
 $ x5 : num  0.805 -2.427 -11.311 2.29 -0.617 ...
 $ x6 : num  6.72 40.48 17.81 -35.11 -16.51 ...
 $ x7 : num  -14.79 -6.73 11.06 -18.91 27.53 ...
 $ x8 : num  -1.041 0.896 5.326 -0.337 1.2 ...
 $ x9 : num  -4.2 0.33 -2.63 -5.57 -4.31 ...
 $ x10: num  6.19 -11.71 1.57 -2 6.67 ...
 $ x11: num  13.25 -2.35 -4.17 -19.29 1.97 ...
 $ x12: num  25.7 -25 12.1 11 -28.1 ...
 $ x13: num  -5.02 9.8 -5.16 -5.91 -1.26 ...
 $ x14: num  10.5 -10.96 7.3 2.51 5.76 ...
 $ x15: num  -2.518 1.504 -2.192 1.292 0.473 ...
 $ x16: num  2.12 -2.4 -4.07 -2.5 -1.15 ...
 $ x17: num  5.87 -9.3 -7.68 -15.72 -14.12 ...
 $ x18: num  -6.67 -2 4.04 -2.74 4.53 ...
 $ x19: num  1.79 5.05 -6.63 1.12 -1.28 ...
 $ x20: num  -1.91 -5.81 1.7 1.92 -9.03 ...
 $ x21: num  -1.74 10.81 -2.42 -14.18 -7.04 ...
 $ x22: num  -2.517 -0.478 2.468 1.471 -1.979 ...
 $ x23: num  3.55 10.59 -5.27 -11.48 -16 ...
 $ x24: chr  "euorpe" "asia" "asia" "asia" ...
 $ x25: num  -0.8013 0.8188 -0.7183 -0.0524 -0.2234 ...
 $ x26: num  1.143 -0.643 -0.567 -0.559 0.351 ...
 $ x27: num  1.005 0.751 4.171 9.216 1.811 ...
 $ x28: num  -18.47 3.75 11.52 30.6 -4.09 ...
 $ x29: chr  "July" "Aug" "July" "July" ...
 $ x30: chr  "tuesday" "wednesday" "wednesday" "wednesday" ...
 $ x31: num  -3.852 1.392 -3.262 -2.285 0.921 ...
 $ x32: chr  "0.0%" "-0.02%" "-0.01%" "0.01%" ...
 $ x33: num  -1.94 2.211 0.42 -3.443 -0.432 ...
 $ x34: num  -5.49 -4.46 -3.8 4.42 12.17 ...
 $ x35: num  0.627 1.035 -0.763 1.165 -0.168 ...
 $ x36: num  -0.874 0.228 -1.613 3.033 -0.342 ...
 $ x37: chr  "$1313.96" "$1962.78" "$430.47" "$-2366.29" ...
 $ x38: num  -1.354 32.817 -0.333 14.189 -12.579 ...
 $ x39: num  -5.19 -5.15 8.73 -6.39 1.13 ...
 $ x40: num  -10.612 2.147 -0.863 12.084 30.005 ...
 $ x41: num  -1.497 36.293 -0.368 15.692 -13.911 ...
 $ x42: num  5.41 4.49 9.09 -7.47 -5.23 ...
 $ x43: num  -2.326 0.763 -0.69 2.941 1.784 ...
 $ x44: num  1.67 6.53 -2.73 -6.42 3.96 ...
 $ x45: num  -0.264 1.008 0.754 0.42 -0.097 ...
 $ x46: num  60.8 15.8 30.9 -72.4 -14.1 ...
 $ x47: num  -7.69 -4.897 -7.429 5.361 -0.208 ...
 $ x48: num  0.152 -0.32 -2.091 1.806 -0.895 ...
 $ x49: num  -8.04 16.72 -7.87 -7.67 15.72 ...
 $ y  : int  0 0 0 0 1 0 1 1 0 1 ...
 - attr(*, "na.action")=Class 'omit'  Named int [1:1466] 30 49 152 153 270 279 336 722 830 861 ...
  .. ..- attr(*, "names")= chr [1:1466] "30" "49" "152" "153" ...
> 
> #7 select list of variables to drop from the model
> drop.cols <- c("x0", "x37",
+                "x1",
+                "x10",
+                "x11",
+                "x13",
+                "x14",
+                "x15",
+                "x16",
+                "x17",
+                "x18",
+                "x19",
+                "x21",
+                "x22",
+                "x24",
+                "x25",
+                "x26",
+                "x27",
+                "x28",
+                "x29",
+                "x3",
+                "x30",
+                "x31",
+                "x32",
+                "x33",
+                "x34",
+                "x35",
+                "x36",
+                "x39",
+                "x4",
+                "x43",
+                "x44",
+                "x45",
+                "x47",
+                "x48",
+                "x5",
+                "x7",
+                "x8",
+                "x9") #to remove multiple columns from model
> 
> train<-train[, !names(train) %in% drop.cols, drop = F]
> 
> str(train)
'data.frame':	158534 obs. of  12 variables:
 $ x2 : num  4.62 27.84 12.25 -24.15 -11.35 ...
 $ x6 : num  6.72 40.48 17.81 -35.11 -16.51 ...
 $ x12: num  25.7 -25 12.1 11 -28.1 ...
 $ x20: num  -1.91 -5.81 1.7 1.92 -9.03 ...
 $ x23: num  3.55 10.59 -5.27 -11.48 -16 ...
 $ x38: num  -1.354 32.817 -0.333 14.189 -12.579 ...
 $ x40: num  -10.612 2.147 -0.863 12.084 30.005 ...
 $ x41: num  -1.497 36.293 -0.368 15.692 -13.911 ...
 $ x42: num  5.41 4.49 9.09 -7.47 -5.23 ...
 $ x46: num  60.8 15.8 30.9 -72.4 -14.1 ...
 $ x49: num  -8.04 16.72 -7.87 -7.67 15.72 ...
 $ y  : int  0 0 0 0 1 0 1 1 0 1 ...
> library(randomForest)
randomForest 4.6-12
Type rfNews() to see new features/changes/bug fixes.
> set.seed(300)
> rf <- randomForest(y ~ x2+x6+x12+x20+x23+x38+x40+x41+x42+x46+x49, data = train)
Warning message:
In randomForest.default(m, y, ...) :
  The response has five or fewer unique values.  Are you sure you want to do regression?
> rf

Call:
 randomForest(formula = y ~ x2 + x6 + x12 + x20 + x23 + x38 +      x40 + x41 + x42 + x46 + x49, data = train) 
               Type of random forest: regression
                     Number of trees: 500
No. of variables tried at each split: 3

          Mean of squared residuals: 0.0918522
                    % Var explained: 61.77
> rf

Call:
 randomForest(formula = y ~ x2 + x6 + x12 + x20 + x23 + x38 +      x40 + x41 + x42 + x46 + x49, data = train) 
               Type of random forest: regression
                     Number of trees: 500
No. of variables tried at each split: 3

          Mean of squared residuals: 0.0918522
                    % Var explained: 61.77
> importance(rf)
    IncNodePurity
x2       2311.943
x6       2270.616
x12      3345.286
x20      4287.407
x23      4854.874
x38      2336.923
x40      3238.036
x41      2382.008
x42      3794.677
x46      3467.934
x49      4102.895